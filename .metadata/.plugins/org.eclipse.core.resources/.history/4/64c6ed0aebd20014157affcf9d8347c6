/* This file was generated with JastAdd2 (http://jastadd.org) version 2.1.4 */
package abs.frontend.ast;

import java.io.PrintStream;
import beaver.Symbol;
import java.io.*;
import abs.frontend.ast.*;
import abs.backend.erlang.*;
import java.util.Iterator;
import abs.frontend.typechecker.locationtypes.infer.LocationTypeInferrerExtension;
import abs.frontend.typechecker.locationtypes.infer.LocationTypeVariable;
import abs.frontend.typechecker.locationtypes.LocationType;
import abs.backend.erlang.ErlUtil.Mask;
import org.apache.commons.io.output.WriterOutputStream;
import java.nio.charset.Charset;
import com.google.common.collect.ImmutableSet;
import com.google.common.collect.Lists;
import abs.backend.java.*;
import abs.backend.java.codegeneration.*;
import abs.backend.java.lib.runtime.*;
import abs.backend.java.lib.expr.*;
import abs.backend.java.lib.types.*;
import abs.backend.java.codegeneration.dynamic.*;
import abs.backend.java.codegeneration.JavaCode;
import abs.backend.java.codegeneration.JavaCodeGenerationException;
import java.util.Set;
import java.util.TreeSet;
import abs.backend.maude.MaudeCompiler;
import abs.backend.maude.MaudeCompilerHelper;
import java.io.PrintWriter;
import abs.backend.prettyprint.*;
import abs.backend.prolog.*;
import static abs.backend.prolog.PrologBackend.fieldTransform;
import static abs.backend.prolog.PrologBackend.initialToUpperCase;
import static abs.backend.prolog.PrologBackend.varTransform;
import static abs.backend.prolog.PrologBackend.strTransform;
import static abs.backend.prolog.PrologBackend.quote;
import java.util.HashSet;
import java.util.Collection;
import java.util.ArrayList;
import abs.frontend.analyser.*;
import abs.frontend.typechecker.*;
import java.util.Collections;
import java.util.Map;
import abs.common.*;
import abs.frontend.typechecker.Type;
import abs.frontend.typechecker.DataTypeType;
import abs.frontend.ast.InterfaceDecl;
import java.util.HashMap;
import abs.frontend.delta.*;
import abs.frontend.parser.*;
import abs.frontend.mtvl.ChocoSolver;
import choco.Choco;
import choco.kernel.model.constraints.Constraint;
import choco.kernel.model.variables.integer.IntegerVariable;
import choco.kernel.model.variables.integer.IntegerExpressionVariable;
import abs.frontend.mtvl.Types;
import abs.frontend.parser.ParserError;
import java.util.*;
import java.util.regex.*;
import abs.frontend.tests.*;
import abs.frontend.treecopy.ParseTreeCopyHelper;
import abs.frontend.analyser.ErrorMessage;
import abs.frontend.analyser.TypeError;
import abs.frontend.typechecker.TypeCheckerHelper;
import abs.frontend.typechecker.KindedName;
import abs.frontend.typechecker.ResolvedName;
import javax.annotation.CheckForNull;
import abs.frontend.typechecker.KindedName.Kind;
import java.util.Arrays;
import abs.frontend.typechecker.ext.*;
/**
 * @ast node
 * @declaredat /Users/vmastand/Documents/JavaProject/ABS/abstools/frontend/src/abs/frontend/ast/SQL.ast:47
 * @production SqlAggregateFunction : {@link ASTNode} ::= <span class="component">&lt;Name:String&gt;</span> <span class="component">[{@link SqlTupleScalarFunction}]</span>;

 */
public class SqlAggregateFunction extends ASTNode<ASTNode> implements Cloneable {
  /**
   * @aspect SqlRewrites
   * @declaredat /Users/vmastand/Documents/JavaProject/ABS/abstools/frontend/src/abs/frontend/sql/SqlRewrites.jrag:334
   */
  public PureExp createDbAggregateFunctionExp() throws abs.frontend.sql.SqlRewritingException {
        abs.frontend.sql.AggregateFunctions.FunctionExpGenerator generator =
                abs.frontend.sql.AggregateFunctions.getExpGeneratorForFunctionName(getName());
        if (generator == null)
            throw new abs.frontend.sql.SqlRewritingException(new SemanticError(this,
                    ErrorMessage.SQL_UNKNOWN_AGGREGATE_FUNCTION, getName()));
        return generator.createDbAggregateFunctionExp(
            hasSqlTupleScalarFunction() ? getSqlTupleScalarFunction() : null);
    }
  /**
   * @declaredat ASTNode:1
   */
  public SqlAggregateFunction() {
    super();
  }
  /**
   * Initializes the child array to the correct size.
   * Initializes List and Opt nta children.
   * @apilevel internal
   * @ast method
   * @declaredat ASTNode:10
   */
  public void init$Children() {
    children = new ASTNode[1];
    setChild(new Opt(), 0);
  }
  /**
   * @declaredat ASTNode:14
   */
  public SqlAggregateFunction(String p0, Opt<SqlTupleScalarFunction> p1) {
    setName(p0);
    setChild(p1, 0);
  }
  /**
   * @declaredat ASTNode:18
   */
  public SqlAggregateFunction(beaver.Symbol p0, Opt<SqlTupleScalarFunction> p1) {
    setName(p0);
    setChild(p1, 0);
  }
  /**
   * @apilevel low-level
   * @declaredat ASTNode:25
   */
  protected int numChildren() {
    return 1;
  }
  /**
   * @apilevel internal
   * @declaredat ASTNode:31
   */
  public boolean mayHaveRewrite() {
    return false;
  }
  /**
   * @apilevel low-level
   * @declaredat ASTNode:37
   */
  public void flushCache() {
    super.flushCache();
  }
  /**
   * @apilevel internal
   * @declaredat ASTNode:43
   */
  public void flushCollectionCache() {
    super.flushCollectionCache();
  }
  /**
   * @apilevel internal
   * @declaredat ASTNode:49
   */
  public SqlAggregateFunction clone() throws CloneNotSupportedException {
    SqlAggregateFunction node = (SqlAggregateFunction) super.clone();
    node.in$Circle(false);
    node.is$Final(false);
    return node;
  }
  /**
   * @apilevel internal
   * @declaredat ASTNode:58
   */
  public SqlAggregateFunction copy() {
    try {
      SqlAggregateFunction node = (SqlAggregateFunction) clone();
      node.parent = null;
      if(children != null) {
        node.children = (ASTNode[]) children.clone();
      }
      return node;
    } catch (CloneNotSupportedException e) {
      throw new Error("Error: clone not supported for " + getClass().getName());
    }
  }
  /**
   * Create a deep copy of the AST subtree at this node.
   * The copy is dangling, i.e. has no parent.
   * @return dangling copy of the subtree at this node
   * @apilevel low-level
   * @declaredat ASTNode:76
   */
  public SqlAggregateFunction fullCopy() {
    SqlAggregateFunction tree = (SqlAggregateFunction) copy();
    if (children != null) {
      for (int i = 0; i < children.length; ++i) {
        ASTNode child = (ASTNode) children[i];
        if(child != null) {
          child = child.fullCopy();
          tree.setChild(child, i);
        }
      }
    }
    return tree;
  }
  /**
   * Replaces the lexeme Name.
   * @param value The new value for the lexeme Name.
   * @apilevel high-level
   */
  public void setName(String value) {
    tokenString_Name = value;
  }
  /**
   * @apilevel internal
   */
  protected String tokenString_Name;
  /**
   */
  public int Namestart;
  /**
   */
  public int Nameend;
  /**
   * JastAdd-internal setter for lexeme Name using the Beaver parser.
   * @param symbol Symbol containing the new value for the lexeme Name
   * @apilevel internal
   */
  public void setName(beaver.Symbol symbol) {
    if(symbol.value != null && !(symbol.value instanceof String))
    throw new UnsupportedOperationException("setName is only valid for String lexemes");
    tokenString_Name = (String)symbol.value;
    Namestart = symbol.getStart();
    Nameend = symbol.getEnd();
  }
  /**
   * Retrieves the value for the lexeme Name.
   * @return The value for the lexeme Name.
   * @apilevel high-level
   */
  public String getName() {
    return tokenString_Name != null ? tokenString_Name : "";
  }
  /**
   * Replaces the optional node for the SqlTupleScalarFunction child. This is the <code>Opt</code>
   * node containing the child SqlTupleScalarFunction, not the actual child!
   * @param opt The new node to be used as the optional node for the SqlTupleScalarFunction child.
   * @apilevel low-level
   */
  public void setSqlTupleScalarFunctionOpt(Opt<SqlTupleScalarFunction> opt) {
    setChild(opt, 0);
  }
  /**
   * Replaces the (optional) SqlTupleScalarFunction child.
   * @param node The new node to be used as the SqlTupleScalarFunction child.
   * @apilevel high-level
   */
  public void setSqlTupleScalarFunction(SqlTupleScalarFunction node) {
    getSqlTupleScalarFunctionOpt().setChild(node, 0);
  }
  /**
   * Check whether the optional SqlTupleScalarFunction child exists.
   * @return {@code true} if the optional SqlTupleScalarFunction child exists, {@code false} if it does not.
   * @apilevel high-level
   */
  public boolean hasSqlTupleScalarFunction() {
    return getSqlTupleScalarFunctionOpt().getNumChild() != 0;
  }
  /**
   * Retrieves the (optional) SqlTupleScalarFunction child.
   * @return The SqlTupleScalarFunction child, if it exists. Returns {@code null} otherwise.
   * @apilevel low-level
   */
  public SqlTupleScalarFunction getSqlTupleScalarFunction() {
    return (SqlTupleScalarFunction) getSqlTupleScalarFunctionOpt().getChild(0);
  }
  /**
   * Retrieves the optional node for the SqlTupleScalarFunction child. This is the <code>Opt</code> node containing the child SqlTupleScalarFunction, not the actual child!
   * @return The optional node for child the SqlTupleScalarFunction child.
   * @apilevel low-level
   */
  public Opt<SqlTupleScalarFunction> getSqlTupleScalarFunctionOpt() {
    return (Opt<SqlTupleScalarFunction>) getChild(0);
  }
  /**
   * Retrieves the optional node for child SqlTupleScalarFunction. This is the <code>Opt</code> node containing the child SqlTupleScalarFunction, not the actual child!
   * <p><em>This method does not invoke AST transformations.</em></p>
   * @return The optional node for child SqlTupleScalarFunction.
   * @apilevel low-level
   */
  public Opt<SqlTupleScalarFunction> getSqlTupleScalarFunctionOptNoTransform() {
    return (Opt<SqlTupleScalarFunction>) getChildNoTransform(0);
  }
  /**
   * @apilevel internal
   */
  public ASTNode rewriteTo() {    return super.rewriteTo();
  }}
